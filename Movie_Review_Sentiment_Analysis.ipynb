{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T03:33:06.416472200Z",
     "start_time": "2025-09-29T03:33:06.369720900Z"
    }
   },
   "id": "bb62f522c2293960"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:30.269419Z",
     "start_time": "2025-09-29T02:17:29.137947Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\ANAKIN\\.cache\\huggingface\\datasets\\imdb\\plain_text\\0.0.0\\e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Sat Sep 27 03:34:18 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 20000, Val size: 5000, Test size: 25000\n"
     ]
    }
   ],
   "source": [
    "# Load IMDB dataset\n",
    "imdb = load_dataset(\"imdb\")\n",
    "full_train = imdb[\"train\"]\n",
    "\n",
    "# Split full train into train + validation\n",
    "split = full_train.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_data = split[\"train\"]   # 80% of full_train\n",
    "val_data   = split[\"test\"]    # 20% of full_train\n",
    "test_data  = imdb[\"test\"]     # official test set\n",
    "\n",
    "print(f\"Train size: {len(train_data)}, Val size: {len(val_data)}, Test size: {len(test_data)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.051844900Z",
     "start_time": "2025-09-29T02:17:29.169501600Z"
    }
   },
   "id": "cc00d15f4dc32bb5"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Tokenizer (simple whitespace)\n",
    "def simple_tokenizer(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.079659800Z",
     "start_time": "2025-09-29T02:17:41.051844900Z"
    }
   },
   "id": "35217597072dfdc"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def build_vocab(dataset, max_size=20000, min_freq=2):\n",
    "    counter = Counter()\n",
    "    for example in dataset:\n",
    "        counter.update(simple_tokenizer(example[\"text\"]))\n",
    "    itos = [\"<pad>\", \"<unk>\"]\n",
    "    for word, freq in counter.most_common(max_size - len(itos)):\n",
    "        if freq >= min_freq:\n",
    "            itos.append(word)\n",
    "    stoi = {w: i for i, w in enumerate(itos)}\n",
    "    return stoi, itos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.191030500Z",
     "start_time": "2025-09-29T02:17:41.063416100Z"
    }
   },
   "id": "37afb367e654fc32"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def encode(text, max_len=200):\n",
    "    tokens = simple_tokenizer(text)\n",
    "    ids = [stoi.get(tok, 1) for tok in tokens]  # 1 = <unk>\n",
    "    return torch.tensor(ids[:max_len], dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.239194500Z",
     "start_time": "2025-09-29T02:17:41.099803Z"
    }
   },
   "id": "78a5791fb6765cf0"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    text_list, label_list, lengths = [], [], []\n",
    "    for example in batch:\n",
    "        ids = encode(example[\"text\"])\n",
    "        text_list.append(ids)\n",
    "        label_list.append(example[\"label\"])\n",
    "        lengths.append(len(ids))\n",
    "    text_list = pad_sequence(text_list, batch_first=True, padding_value=0)  # 0 = <pad>\n",
    "    label_list = torch.tensor(label_list, dtype=torch.long)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    return text_list, label_list, lengths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.239194500Z",
     "start_time": "2025-09-29T02:17:41.111380200Z"
    }
   },
   "id": "ed436fb61262074c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6e7e9c3383744d4"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, dropout, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)  # <pad> = 0\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out, (h, c) = self.lstm(packed)\n",
    "        out = self.dropout(h[-1])   # last hidden state\n",
    "        return self.fc(out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.239194500Z",
     "start_time": "2025-09-29T02:17:41.159291Z"
    }
   },
   "id": "e88bf35dc8275d9"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Model\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # *2 for bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out, (h, c) = self.lstm(packed)\n",
    "        # h shape: (num_layers * num_directions, batch, hidden_dim)\n",
    "        h_forward = h[-2]   # last layer forward\n",
    "        h_backward = h[-1]  # last layer backward\n",
    "        h_cat = torch.cat((h_forward, h_backward), dim=1)\n",
    "        return self.fc(self.dropout(h_cat))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-29T02:17:41.136687700Z"
    }
   },
   "id": "3b5d0a73c7c6aa69"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def predict_sentiment(model, text, max_len=200):\n",
    "    model.eval()\n",
    "    # Encode and truncate\n",
    "    tokens = encode(text, max_len=max_len)\n",
    "    length = torch.tensor([len(tokens)], dtype=torch.long)\n",
    "\n",
    "    # Add batch dimension\n",
    "    tokens = tokens.unsqueeze(0)  # shape (1, seq_len)\n",
    "\n",
    "    # Move to device\n",
    "    tokens, length = tokens.to(device), length.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens, length)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        pred_class = probs.argmax(1).item()\n",
    "\n",
    "    return pred_class, probs.squeeze().tolist()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.239194500Z",
     "start_time": "2025-09-29T02:17:41.198531400Z"
    }
   },
   "id": "ae2abb5082a9364c"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_dim = 200\n",
    "hidden_dim = 256\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "lr = 0.005\n",
    "dropout = 0.5\n",
    "weight_decay = 1e-5\n",
    "num_classes = 2\n",
    "\n",
    "patience = 4\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:17:41.349438900Z",
     "start_time": "2025-09-29T02:17:41.207079900Z"
    }
   },
   "id": "be4d3ae964f8a110"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000\n"
     ]
    }
   ],
   "source": [
    "stoi, itos = build_vocab(train_data)\n",
    "vocab_size = len(itos)\n",
    "print(\"Vocab size:\", vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:18:02.548285300Z",
     "start_time": "2025-09-29T02:17:41.236665500Z"
    }
   },
   "id": "1ecf583869abeb76"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# Save stoi (string-to-index mapping)\n",
    "with open(\"vocab.json\", \"w\") as f:\n",
    "    json.dump(stoi, f)\n",
    "\n",
    "# (Optional) also save itos (index-to-string mapping)\n",
    "with open(\"itos.json\", \"w\") as f:\n",
    "    json.dump(itos, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T03:35:51.308819400Z",
     "start_time": "2025-09-29T03:35:51.030871Z"
    }
   },
   "id": "cb8c3eefc5634faf"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "val_dataloader   = DataLoader(val_data,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:18:02.579707800Z",
     "start_time": "2025-09-29T02:18:02.563943800Z"
    }
   },
   "id": "cd2e4f7d8c3b7737"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# LSTM Model, Loss, Optimizer\n",
    "\n",
    "lstm_model = LSTMClassifier(vocab_size, embed_dim, hidden_dim, dropout, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=lr, weight_decay=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:18:02.784518100Z",
     "start_time": "2025-09-29T02:18:02.595836200Z"
    }
   },
   "id": "44872276b9e5f5bf"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.6687, Train Acc 0.5919 | Val Loss 0.6276, Val Acc 0.6364\n",
      "Epoch 2: Train Loss 0.4766, Train Acc 0.7791 | Val Loss 0.3507, Val Acc 0.8510\n",
      "Epoch 3: Train Loss 0.3221, Train Acc 0.8721 | Val Loss 0.3806, Val Acc 0.8534\n",
      "No improvement. Patience counter = 1/4\n",
      "Epoch 4: Train Loss 0.2322, Train Acc 0.9128 | Val Loss 0.3414, Val Acc 0.8614\n",
      "Epoch 5: Train Loss 0.1745, Train Acc 0.9373 | Val Loss 0.3718, Val Acc 0.8556\n",
      "No improvement. Patience counter = 1/4\n",
      "Epoch 6: Train Loss 0.1358, Train Acc 0.9508 | Val Loss 0.3988, Val Acc 0.8532\n",
      "No improvement. Patience counter = 2/4\n",
      "Epoch 7: Train Loss 0.1192, Train Acc 0.9568 | Val Loss 0.4922, Val Acc 0.8552\n",
      "No improvement. Patience counter = 3/4\n",
      "Epoch 8: Train Loss 0.1061, Train Acc 0.9627 | Val Loss 0.4418, Val Acc 0.8572\n",
      "No improvement. Patience counter = 4/4\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM Training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    lstm_model.train()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for texts, labels, lengths in train_dataloader:\n",
    "        texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "        outputs = lstm_model(texts, lengths)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader.dataset)\n",
    "    train_acc = total_correct / len(train_dataloader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    lstm_model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels, lengths in val_dataloader:\n",
    "            texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "            outputs = lstm_model(texts, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss {avg_train_loss:.4f}, Train Acc {train_acc:.4f} | \"\n",
    "          f\"Val Loss {avg_val_loss:.4f}, Val Acc {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(lstm_model.state_dict(), \"best_lstm.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience counter = {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "lstm_model.load_state_dict(torch.load(\"best_lstm.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:27:33.337760300Z",
     "start_time": "2025-09-29T02:18:02.800686400Z"
    }
   },
   "id": "d2771b6970cee908"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# BiLSTM Model, Loss, Optimizer\n",
    "\n",
    "bi_lstm_model = BiLSTMClassifier(vocab_size, embed_dim, hidden_dim, num_classes, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bi_lstm_model.parameters(), lr=lr, weight_decay=weight_decay)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:33:12.863939200Z",
     "start_time": "2025-09-29T02:33:12.628387400Z"
    }
   },
   "id": "7a186ba2f76f1559"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Reset early stopping variables\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:33:13.985972500Z",
     "start_time": "2025-09-29T02:33:13.943668300Z"
    }
   },
   "id": "6e8632a5ed1a9554"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.6416, Train Acc 0.6248 | Val Loss 0.5035, Val Acc 0.7676\n",
      "Epoch 2: Train Loss 0.3846, Train Acc 0.8307 | Val Loss 0.3472, Val Acc 0.8550\n",
      "Epoch 3: Train Loss 0.2479, Train Acc 0.9025 | Val Loss 0.3379, Val Acc 0.8626\n",
      "Epoch 4: Train Loss 0.1718, Train Acc 0.9358 | Val Loss 0.3614, Val Acc 0.8606\n",
      "No improvement. Patience counter = 1/4\n",
      "Epoch 5: Train Loss 0.1237, Train Acc 0.9543 | Val Loss 0.4513, Val Acc 0.8474\n",
      "No improvement. Patience counter = 2/4\n",
      "Epoch 6: Train Loss 0.0995, Train Acc 0.9607 | Val Loss 0.4661, Val Acc 0.8468\n",
      "No improvement. Patience counter = 3/4\n",
      "Epoch 7: Train Loss 0.0907, Train Acc 0.9670 | Val Loss 0.4426, Val Acc 0.8404\n",
      "No improvement. Patience counter = 4/4\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BiLSTM training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    bi_lstm_model.train()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for texts, labels, lengths in train_dataloader:\n",
    "        texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "        outputs = bi_lstm_model(texts, lengths)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader.dataset)\n",
    "    train_acc = total_correct / len(train_dataloader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    bi_lstm_model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels, lengths in val_dataloader:   \n",
    "            texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "            outputs = bi_lstm_model(texts, lengths)             \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss {avg_train_loss:.4f}, Train Acc {train_acc:.4f} | \"\n",
    "          f\"Val Loss {avg_val_loss:.4f}, Val Acc {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(bi_lstm_model.state_dict(), \"best_bilstm.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience counter = {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "bi_lstm_model.load_state_dict(torch.load(\"best_bilstm.pt\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:45:50.871496Z",
     "start_time": "2025-09-29T02:33:15.596465400Z"
    }
   },
   "id": "60f6a058663d9e06"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM    Test Loss: 0.3865, Test Accuracy: 0.8429\n",
      "BiLSTM  Test Loss: 0.3849, Test Accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of both models\n",
    "lstm_model.eval()\n",
    "bi_lstm_model.eval()\n",
    "\n",
    "lstm_test_loss, lstm_correct, lstm_total = 0, 0, 0\n",
    "bi_lstm_test_loss, bi_lstm_correct, bi_lstm_total = 0, 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels, lengths in test_dataloader:\n",
    "        texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "\n",
    "        # Forward passes\n",
    "        lstm_outputs = lstm_model(texts, lengths)\n",
    "        bi_lstm_outputs = bi_lstm_model(texts, lengths)\n",
    "\n",
    "        # Losses\n",
    "        lstm_loss = criterion(lstm_outputs, labels)\n",
    "        bi_lstm_loss = criterion(bi_lstm_outputs, labels)\n",
    "\n",
    "        # Accumulate for LSTM\n",
    "        lstm_test_loss += lstm_loss.item() * labels.size(0)\n",
    "        lstm_correct += (lstm_outputs.argmax(1) == labels).sum().item()\n",
    "        lstm_total += labels.size(0)\n",
    "\n",
    "        # Accumulate for BiLSTM\n",
    "        bi_lstm_test_loss += bi_lstm_loss.item() * labels.size(0)\n",
    "        bi_lstm_correct += (bi_lstm_outputs.argmax(1) == labels).sum().item()\n",
    "        bi_lstm_total += labels.size(0)\n",
    "\n",
    "print(f\"LSTM    Test Loss: {lstm_test_loss/lstm_total:.4f}, Test Accuracy: {lstm_correct/lstm_total:.4f}\")\n",
    "print(f\"BiLSTM  Test Loss: {bi_lstm_test_loss/bi_lstm_total:.4f}, Test Accuracy: {bi_lstm_correct/bi_lstm_total:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:48:00.182126300Z",
     "start_time": "2025-09-29T02:46:52.746465200Z"
    }
   },
   "id": "a9c2852820d204d2"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM : Prediction: Negative\n",
      "Probabilities: [0.9793155193328857, 0.02068454399704933]\n",
      "BiLSTM : Prediction: Negative\n",
      "Probabilities: [0.9854004979133606, 0.014599491842091084]\n"
     ]
    }
   ],
   "source": [
    "# Model Testing for a sample movie review\n",
    "\n",
    "review = \"The movie was awfully boring, cannot recommend it.\"\n",
    "\n",
    "# LSTM prediction\n",
    "pred_class_lstm, probs_lstm = predict_sentiment(lstm_model, review)\n",
    "print(\"LSTM : Prediction:\", \"Positive\" if pred_class_lstm == 1 else \"Negative\")\n",
    "print(\"Probabilities:\", probs_lstm)\n",
    "\n",
    "# BiLSTM prediction\n",
    "pred_class_bi, probs_bi = predict_sentiment(bi_lstm_model, review)\n",
    "print(\"BiLSTM : Prediction:\", \"Positive\" if pred_class_bi == 1 else \"Negative\")\n",
    "print(\"Probabilities:\", probs_bi)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-29T02:49:29.505820900Z",
     "start_time": "2025-09-29T02:49:29.255684Z"
    }
   },
   "id": "9aaafc5b081a8f59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6f617aee71fc0f27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
